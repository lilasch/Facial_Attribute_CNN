Facial Attribute Classification by Lila Schisgal and Phoebe Jeske

With this project, we sought to create a convolutional neural network capable 
of recognizing forty different facial attributes. We did this by using the Large-
Scale CelebFaces Attributes Dataset, a collection of more than 200.000 labelled
images.

The images were previously marked as training, validation, and test. We initially
processed them by moving them into folders based on their classification, 
flattening them, and then performed standardization using the mean from the 
training set. However, as accessing each image proved to be too large a computation 
load for our system, we switched to processing them via a series of generators: one 
for the train data, one for the valid data, and one for the test data. This enabled
us to rescale and access all of our data without loading in each individual image.

Our initial model was a sequential model with two Conv2D laters, a Flatten layer,
a Dropout Layer, and 2 Dense Layers. It used adam as its optimizer and binary
crossentropy for the loss, as since the categories are neither exclusive nor related,
what we require of our model is 40 separate binary classifications. We programmed
in early stopping; however, due to the tremendous computational load, for the sake
of evaluation we ultimately stopped it after one epoch to ensure we had some results.
This produced a test accuracy of 0.0149.

Using sklearn's classification_report, we found this initial model to have a 
weighted average precision of 0.41, recall of 0.32, and f-1 score of 0.34.

To update our model, we updated it to use a pretrained model with transfer learning
from resnet50. We still used adam as our optimizer and binary cross entropy. We
ran one epoch of this training as well, due to the same computational load issues.

We have thus far been unable to run classification_report on this due to
computational load.

In addition to evaluation via classification_report, we introduced both quantitative
and visual checks. We created confusion matrices for each of the attributes. We 
found that with the low accuracy, our model was largely teaching itself to predict
all 0s. We had very few false positives, and for many attributes none. Beyond
further training, it would be helpful to us to tweak the thresholds our model
recognizes as positive and negative.

We also introduced the ability to predict with custom photos. This enabled us to
take images we both know and can see the label to, and see how our model fared in
comparison. Two sample images are available in the repository, Lila.png and Sam.jpg.

Ultimately, our model suffered greatly from a lack of resources. Training on more
than one epoch would be critical to improving our accuracy, especially given the
complexity of our data and the large number of outputs we were working with.


