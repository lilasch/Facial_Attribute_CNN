{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilasch/Facial_Attribute_CNN/blob/main/basicmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUz8sUaAIqQj"
      },
      "source": [
        "**Facial Attribute Classification**\n",
        "\n",
        "Lila Schisgal and Phoebe Jeske\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEiHEhSWtsT0"
      },
      "source": [
        "First, we import our data from two text files and partition it into training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-AnqGT9HudD",
        "outputId": "86a46279-18c6-434c-ccf8-39ebec537f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-53-c78c5ea5c41d>:14: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  attributes = pd.read_csv(\"/content/drive/MyDrive/list_attr_celeba.txt\", skiprows = 1, delimiter=\"\\s+|\\t\")\n",
            "<ipython-input-53-c78c5ea5c41d>:17: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  partitions = pd.read_csv(\"/content/drive/MyDrive/list_eval_partition.txt\", delimiter=\"\\s+|\\t\", header = None)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
        "import tensorflow\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "# Load attributes csv\n",
        "attributes = pd.read_csv(\"list_attr_celeba.txt\", skiprows = 1, delimiter=\"\\s+|\\t\")\n",
        "\n",
        "# Load csv with partitions values\n",
        "partitions = pd.read_csv(\"list_eval_partition.txt\", delimiter=\"\\s+|\\t\", header = None)\n",
        "\n",
        "partitions.columns = ['image_name', 'dataset'] # setting column header names for partitions\n",
        "attributes['dataset'] = partitions['dataset'].values # copying the partition values into the attributes df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmZnyF124m-G"
      },
      "outputs": [],
      "source": [
        "# unzipping image data\n",
        "import zipfile\n",
        "zippath = 'img_align_celeba.zip'\n",
        "targetfolder = 'all_images'\n",
        "\n",
        "with zipfile.ZipFile(zippath, 'r') as zip_ref:\n",
        "    zip_ref.extractall(targetfolder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJqWv68bdruA"
      },
      "outputs": [],
      "source": [
        "# filter so just the eyeglasses attribute is included\n",
        "glasses_df = attributes.iloc[:, [15, 40]] # 40 attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6k_kIMEdGsV"
      },
      "outputs": [],
      "source": [
        "# the image filenames need to be in their own column\n",
        "glasses_df = glasses_df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "y8VdCTrMdv8I",
        "outputId": "ee52ccd6-2412-41d5-d151-db2a41192b35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-56-fa326fac323d>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train.drop(columns='dataset', inplace=True)\n",
            "<ipython-input-56-fa326fac323d>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid.drop(columns='dataset', inplace=True)\n",
            "<ipython-input-56-fa326fac323d>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test.drop(columns='dataset', inplace=True)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntrain_labels = train.loc[:,'eyeglasses_or_not']\\nvalid_labels = valid.loc[:,'eyeglasses_or_not']\\ntest_labels = test.loc[:,'eyeglasses_or_not']\\ny_train=keras.utils.to_categorical(train_labels)\\ny_valid=keras.utils.to_categorical(valid_labels)\\ny_test=keras.utils.to_categorical(test_labels)\""
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# rename columns\n",
        "glasses_df.rename(columns={'index': 'image_names'}, inplace=True)\n",
        "glasses_df.rename(columns={'Eyeglasses': 'eyeglasses_or_not'}, inplace=True)\n",
        "\n",
        "# splitting the data\n",
        "train = glasses_df[glasses_df['dataset'] == 0]\n",
        "train.drop(columns='dataset', inplace=True)\n",
        "valid = glasses_df[glasses_df['dataset'] == 1]\n",
        "valid.drop(columns='dataset', inplace=True)\n",
        "test = glasses_df[glasses_df['dataset'] == 2]\n",
        "test.drop(columns='dataset', inplace=True)\n",
        "\n",
        "'''\n",
        "train_labels = train.loc[:,'eyeglasses_or_not']\n",
        "valid_labels = valid.loc[:,'eyeglasses_or_not']\n",
        "test_labels = test.loc[:,'eyeglasses_or_not']\n",
        "y_train=keras.utils.to_categorical(train_labels)\n",
        "y_valid=keras.utils.to_categorical(valid_labels)\n",
        "y_test=keras.utils.to_categorical(test_labels)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GihQSrpiZt4E",
        "outputId": "c1be55d5-f279-4538-b7b9-4557d5ad11c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-61-6f77becb2fd9>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[\"eyeglasses_or_not\"] = train[\"eyeglasses_or_not\"].astype('str') # requires target in string format\n",
            "<ipython-input-61-6f77becb2fd9>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid[\"eyeglasses_or_not\"] = valid[\"eyeglasses_or_not\"].astype('str')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 162770 validated image filenames belonging to 2 classes.\n",
            "Found 19867 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator() # ImageDataGenerator for train\n",
        "valid_datagen = ImageDataGenerator() # ImageDataGenerator for valid\n",
        "\n",
        "train[\"eyeglasses_or_not\"] = train[\"eyeglasses_or_not\"].astype('str') # requires target in string format\n",
        "valid[\"eyeglasses_or_not\"] = valid[\"eyeglasses_or_not\"].astype('str')\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=train,\n",
        "                                              directory='all_images/img_align_celeba/',\n",
        "                                              x_col=\"image_names\",\n",
        "                                              y_col=\"eyeglasses_or_not\",\n",
        "                                              subset=\"training\",\n",
        "                                              class_mode=\"binary\",\n",
        "                                              batch_size=64,\n",
        "                                              rescale=1.0/255,\n",
        "                                              target_size=(109,89)\n",
        "                                              )\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_dataframe(dataframe=valid,\n",
        "                                              directory='all_images/img_align_celeba/',\n",
        "                                              x_col=\"image_names\",\n",
        "                                              y_col=\"eyeglasses_or_not\",\n",
        "                                              class_mode=\"binary\",\n",
        "                                              batch_size=64,\n",
        "                                              rescale=1.0/255,\n",
        "                                              target_size=(109,89)\n",
        "                                              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8O6s1cg0hix",
        "outputId": "5c9a15c8-0adc-4489-e2da-ca783f9c4c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_23 (Conv2D)          (None, 109, 89, 75)       2100      \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 109, 89, 50)       33800     \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 485050)            0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 32)                15521632  \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15557565 (59.35 MB)\n",
            "Trainable params: 15557565 (59.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\",\n",
        "                 input_shape=(109, 89, 3)))\n",
        "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=32, activation=\"relu\"))\n",
        "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0DiR9hHbW7u",
        "outputId": "f788bde1-b357-4d87-acdc-aeac48b45cb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-63-10047e0ea62a>:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=train_generator,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1110/2543 [============>.................] - ETA: 1:17:21 - loss: 1.4382 - accuracy: 0.9346"
          ]
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(generator=train_generator,\n",
        "          epochs=20,\n",
        "          steps_per_epoch=train.shape[0]//64,\n",
        "          validation_data=valid_generator,\n",
        "          validation_steps=valid.shape[0]//64,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx3tdo-ptvGs"
      },
      "source": [
        "DEFUNCT CODE BELOW:\n",
        "\n",
        "We then separate our target y values and image filenames in preparation for accessing the actual images as vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0vb_sfmtinnR",
        "outputId": "913b0e4a-dcf7-4d29-a7d9-04713c338bc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1155, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1249, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 723, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/accuracy_metrics.py\", line 459, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 969, in sparse_categorical_matches\n        matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n\n    ValueError: Dimensions must be equal, but are 2 and 178 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](IteratorGetNext:1, Cast_1)' with input shapes: [?,2], [?,218,178].\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c4fda00f8c5f>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m history = model.fit(x_train,\n\u001b[0m\u001b[1;32m      8\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1155, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1249, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 723, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/accuracy_metrics.py\", line 459, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 969, in sparse_categorical_matches\n        matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n\n    ValueError: Dimensions must be equal, but are 2 and 178 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](IteratorGetNext:1, Cast_1)' with input shapes: [?,2], [?,218,178].\n"
          ]
        }
      ],
      "source": [
        "# Fit\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=25,\n",
        "                    validation_data=(x_valid,y_valid),\n",
        "                    batch_size=32,\n",
        "                    verbose=1)\n",
        "\n",
        "# '''\n",
        "# early_stopping = keras.callbacks.EarlyStopping(\n",
        "#     patience=5,\n",
        "#     min_delta=0.001,\n",
        "#     restore_best_weights=True,\n",
        "# )\n",
        "\n",
        "# network_history_std = model.fit(x_train, y_train, validation_data=(x_valid,y_valid),\n",
        "#                                 epochs=1000000000, callbacks=[early_stopping])'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MthRR0smTS8V"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# getting our image file names in three arrays\n",
        "# train_files = train_df.index\n",
        "# valid_files = valid_df.index\n",
        "# test_files = test_df.index\n",
        "\n",
        "\n",
        "image_folder = \"/content/all_images/img_align_celeba\"\n",
        "valid_folder = \"/content/drive/MyDrive/valid_images\"\n",
        "train_folder = \"/content/drive/MyDrive/train_images\"\n",
        "test_folder = \"/content/drive/MyDrive/test_images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnYKid1Y11Z0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Function to split images based on classification\n",
        "def split_images(source_folder):\n",
        "    files = os.listdir()  # Get the list of files in the source_folder\n",
        "    for file in files:\n",
        "        if file in train_files:\n",
        "            if not os.path.exists(os.path.join(train_folder, file)):\n",
        "                shutil.move(os.path.join(source_folder, file), os.path.join(train_folder, file))\n",
        "        elif file in valid_files:\n",
        "              if not os.path.exists(os.path.join(valid_folder, file)):\n",
        "                  shutil.move(os.path.join(source_folder, file), os.path.join(valid_folder, file))\n",
        "        elif file in test_files:\n",
        "              if not os.path.exists(os.path.join(test_folder, file)):\n",
        "                  shutil.move(os.path.join(source_folder, file), os.path.join(test_folder, file))\n",
        "\n",
        "\n",
        "split_images(image_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cARSstsgtz11"
      },
      "source": [
        "Next: need to access the images from the dataset and put them into a set of vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "HD7futHFwkgc",
        "outputId": "3fb18bc4-a039-46d6-f890-3664f0831656"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'values'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-a92a819f6a3d>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# getting x_train and y_train as separate arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# building a dataframe for training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
          ]
        }
      ],
      "source": [
        "from re import X\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# separating out target values\n",
        "y_train = train_df['Eyeglasses']\n",
        "y_valid = valid_df['Eyeglasses']\n",
        "y_test = test_df['Eyeglasses']\n",
        "\n",
        "# getting x_train and y_train as separate arrays\n",
        "x_train = train_df.index.to_numpy()\n",
        "y_train = y_train.values\n",
        "\n",
        "# building a dataframe for training data\n",
        "train_df = pd.DataFrame(columns=['image_name','eyeglasses_or_not'])\n",
        "train_df['image_name'] = x_train\n",
        "train_df['eyeglasses_or_not'] = y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0ISxhWhYvBw"
      },
      "source": [
        "Now, for the ImageDataGenerator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V01d2oODYyKc",
        "outputId": "e2039a40-6d37-409c-8d86-95da95644482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 validated image filenames belonging to 0 classes.\n",
            "(0, 256, 256, 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 162770 invalid image filename(s) in x_col=\"image_name\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Invalid shape (0, 256, 256, 3) for image data",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-53538a9038fd>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;31m# plot raw pixel data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m   \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5663\u001b[0m                               **kwargs)\n\u001b[1;32m   5664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5665\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5666\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    708\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    709\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 710\u001b[0;31m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[1;32m    711\u001b[0m                             .format(self._A.shape))\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (0, 256, 256, 3) for image data"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x1500 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "'''\n",
        "# plotting images\n",
        "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(15,15))\n",
        "\n",
        "for i in range(4):\n",
        "\n",
        "  # convert to unsigned integers for plotting\n",
        "  image = next(train_generator_df)[0].astype('uint8')\n",
        "\n",
        "  # changing size from (1, 200, 200, 3) to (200, 200, 3) for plotting the image\n",
        "  image = np.squeeze(image)\n",
        "\n",
        "  # plot raw pixel data\n",
        "  ax[i].imshow(image)\n",
        "  ax[i].axis('off')'''\n",
        "\n",
        "'''\n",
        "# Function to normalize images\n",
        "def normalize_images(image_path):\n",
        "    save_array = []\n",
        "    for filename in os.listdir(image_path):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(image_path, filename)\n",
        "            img = Image.open(img_path)\n",
        "            img_array = np.array(img)\n",
        "            flattened_dim = 218 * 178 * 3\n",
        "            img_processed = img_array.reshape(-1, flattened_dim)\n",
        "            img_processed = img_processed.astype(float)\n",
        "            save_array.append(img_processed)\n",
        "    return save_array\n",
        "\n",
        "def standardize(train, test, valid):\n",
        "    mean = np.mean(train)\n",
        "    std = np.std(train)\n",
        "\n",
        "    train = (train - mean)/std\n",
        "    valid = (valid - mean)/std\n",
        "    test = (test - mean)/std\n",
        "\n",
        "    return train, test, valid\n",
        "\n",
        "# Apply preprocessing steps\n",
        "valid_images = normalize_images(valid_folder)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dqzHxfkq18P"
      },
      "outputs": [],
      "source": [
        "# test_images = normalize_images(test_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtdLBwwxqz-w"
      },
      "outputs": [],
      "source": [
        "# train_images = normalize_images(train_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3-AuEXHqzV4"
      },
      "outputs": [],
      "source": [
        "# x_train, x_test, x_valid = standardize(train_images, test_images, valid_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii2ZRzDswvAP"
      },
      "outputs": [],
      "source": [
        "eval = model.evaluate(x_test,y_test)\n",
        "print(\"Test loss:\",eval[0])\n",
        "print(\"Test accuracy:\",eval[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3jPbvGAUa0g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}